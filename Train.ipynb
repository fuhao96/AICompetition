{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c5099b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bdd0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.0.112 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.83  Python-3.7.16 torch-1.9.1 CUDA:0 (NVIDIA T1200 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=substack.yaml, epochs=100, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\train25\n",
      "Overriding model.yaml nc=80 with nc=35\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    758137  ultralytics.nn.modules.Detect                [35, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3017673 parameters, 3017657 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\labels\\train... 945 images, 0 backgrounds, 47 corrupt: 100%|██████████| 945/945 [00:00<00:00, 1348.76it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\0ecb0afee47001d7fc35dacec2e2dcb7.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\11fb18bc1541272620efcadf3b7f9886.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\19fc492b22bf0fdb1b114f5d5a55c531.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\1a08e624168ef3a5ae766b8c4995a3b4.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\1ccde0cab5f7c7d51bcd1337322a4273.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\1cff6c2ffc0b298c4e9b95985e24f385.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\1e8b43deca87d25180aba67557735c01.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\1f6fbcfa7ecf5f243c7dc8c05d673548.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\1ff72c66bff0bc173483ba34e3fc906e.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\22e4e202caea8356818600472c961d7b.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2a153dd72eed44cadd83f0bd9b252fbd.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2b80e26d24d077d2877caf97756db72d.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2bb022ad1bd42421bba8b9057cc7cff0.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2cb390e77276c68e9b27405ea26141d5.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2d655d58ae5fe16cc6d7e01f753f46df.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2ed99d6917cc3a481ff316b7f91c17c5.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2f05bf695b2ce4dbdc8157a3cbac9013.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2f0730e107dcf402efab5c63eeeee6a1.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\2fa5676b266a03cf6f5db52f1c6fb01f.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\30bfbd5143b0c508410ff1bffab15833.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\3ba54ccc90ad89edf0d6d7de2fadac6f.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\3dbf1cd0fcb0fdac62530779fffb8124.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\4c8108201bd4bdf513ab7f70e424347e.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\4ef1fa6020f23711cc0e06dc1e7dfdbc.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\4f6335afb880904ed5ebae7ed55fd81b.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\5a459b61dcabf4438232b63acea220ec.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\5bb9e4d2e3f2b872e0f6df453f5cc26e.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\5ceae466241db327b32b92efbadfe4a9.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\5ed8dd35ea5346ac1dc70a726411cd04.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\5f08f63b16372a90aa2d9a2fdd387293.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\6b4062c7de62235aefd1df00b359c3d3.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\6b9d1b690c8a8a1c1bff9a9347087cfa.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\6e0e8a31c842efc0d95763ff69eeae20.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\6f871f1eff142ca082dffef6f71477d8.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7a1054ee4e1158ad3bb2d2d7b1308cc6.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7ac2b5810f1ffa066cd14e0884bc220f.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7b53a9ad6ee74c13b79983cfeffe8553.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7c218365765cccdde2dc3fb589b6796d.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7c74169bbe96c217bf958a57714b5875.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7ecbff1c2622efc7e5c277517e78a3c3.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7f0de79a9885d00c3cfa23bd5d9e1e85.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7f8b02c6c67a7752332cb8d4a4bb4c09.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7fa6c99979716d1b22cabb23ea9c7dd2.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7fb7ec7561b163dadcd51673901e3817.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\7fcad75deab335835b17139e2e6ccd02.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\8caddf2222f5406263efa5723fb5cb15.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\8d2efc53ac993ea174d2b256fb9ec6e6.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\8dc7c5a4ac08bfe1e3f330571ae37f59.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\9b72101ca3c06a71d76a624efea691e2.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\9b7c8ae24dba8a7fb57c2cde64e244f2.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\9ce2a31b33b01556eb4f3bbdf7a9e29e.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\train\\9ff712d97fc2e59847fb6bab23ff2723.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\labels\\train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\labels\\val... 55 images, 0 backgrounds, 5 corrupt: 100%|██████████| 55/55 [00:00<00:00, 1293.74it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\val\\00afb4420bdce881ad216867c713c800.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\val\\0a36e5862664eb92575949fc3ce7f842.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\val\\0af3a80affb05a409c3348a3f3c4986e.jpg: ignoring corrupt image/label: could not convert string to float: 'Mig31'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\val\\0b8b0ab7f2446360d6ae632a2bdef033.jpg: ignoring corrupt image/label: could not convert string to float: 'Mirage2000'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\images\\val\\0ba78273ea691112c50c93b54bbbabe7.jpg: ignoring corrupt image/label: could not convert string to float: 'MQ9'\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\hfu4\\YOLO2COCO\\dataset\\labelImg_dataset_output\\labels\\val.cache\n",
      "Plotting labels to runs\\detect\\train25\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train25\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "  0%|          | 0/57 [00:00<?, ?it/s]C:\\Users\\hfu4\\Anaconda3\\envs\\yolo\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py:445: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)  # clip gradients\n",
      "      1/100      2.31G      1.057      4.603      1.266          3        640: 100%|██████████| 57/57 [01:52<00:00,  1.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.39it/s]\n",
      "                   all         50        108          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/100      2.34G      1.098      4.199      1.278         13        640: 100%|██████████| 57/57 [01:52<00:00,  1.98s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.93it/s]\n",
      "                   all         50        108      0.248      0.161     0.0762     0.0653\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/100      2.29G      1.168      3.958      1.319         67        640:  35%|███▌      | 20/57 [00:42<01:18,  2.12s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10788\\307537872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolov8n.yaml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'yolov8n.pt'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# build from YAML and transfer weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'substack.yaml'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[1;31m# attach optional HUB session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m         \u001b[1;31m# Update model and cfg after training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0mddp_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\yolo\\lib\\site-packages\\ultralytics\\yolo\\engine\\trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    341\u001b[0m                     pbar.set_description(\n\u001b[0;32m    342\u001b[0m                         \u001b[1;33m(\u001b[0m\u001b[1;34m'%11s'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'%11.4g'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m                         (f'{epoch + 1}/{self.epochs}', mem, *losses, batch['cls'].shape[0], batch['img'].shape[-1]))\n\u001b[0m\u001b[0;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_batch_end'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplots\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mni\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_idx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.yaml')  # build a new model from YAML\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "model = YOLO('yolov8n.yaml').load('yolov8n.pt')  # build from YAML and transfer weights\n",
    "\n",
    "model.train(data='substack.yaml', epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458833d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hfu4\\yolov8\n"
     ]
    }
   ],
   "source": [
    "cd yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9deba5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
